{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/zaneprice/Library/Python/3.11/lib/python/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/zaneprice/Library/Python/3.11/lib/python/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python_version>\"3.7\" in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-gpu) (0.0.2)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1v/1ywp4xjx1y116392trcjdvd00000gn/T/pip-install-9p327gpc/tensorflow-gpu_948ad5716b3d442ea6956a5df5b6b18d/setup.py\", line 37, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(TF_REMOVAL_WARNING)\n",
      "  \u001b[31m   \u001b[0m Exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m =========================================================\n",
      "  \u001b[31m   \u001b[0m The \"tensorflow-gpu\" package has been removed!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Please install \"tensorflow\" instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Other than the name, the two packages have been identical\n",
      "  \u001b[31m   \u001b[0m since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "  \u001b[31m   \u001b[0m information, see: pypi.org/project/tensorflow-gpu\n",
      "  \u001b[31m   \u001b[0m =========================================================\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tensorflow-gpu\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n",
      "Installing collected packages: tensorflow-gpu\n",
      "  Running setup.py install for tensorflow-gpu ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for tensorflow-gpu\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/1v/1ywp4xjx1y116392trcjdvd00000gn/T/pip-install-9p327gpc/tensorflow-gpu_948ad5716b3d442ea6956a5df5b6b18d/setup.py\", line 37, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(TF_REMOVAL_WARNING)\n",
      "  \u001b[31m   \u001b[0m Exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m =========================================================\n",
      "  \u001b[31m   \u001b[0m The \"tensorflow-gpu\" package has been removed!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Please install \"tensorflow\" instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Other than the name, the two packages have been identical\n",
      "  \u001b[31m   \u001b[0m since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "  \u001b[31m   \u001b[0m information, see: pypi.org/project/tensorflow-gpu\n",
      "  \u001b[31m   \u001b[0m =========================================================\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m tensorflow-gpu\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/zaneprice/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.12.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install tensorflow-gpu\n",
    "!pip3 install opencv-python\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minterpolation_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Display data as an image, i.e., on a 2D regular raster.\n",
      "\n",
      "The input may either be actual RGB(A) data, or 2D scalar data, which\n",
      "will be rendered as a pseudocolor image. For displaying a grayscale\n",
      "image set up the colormapping using the parameters\n",
      "``cmap='gray', vmin=0, vmax=255``.\n",
      "\n",
      "The number of pixels used to render an image is set by the Axes size\n",
      "and the *dpi* of the figure. This can lead to aliasing artifacts when\n",
      "the image is resampled because the displayed image size will usually\n",
      "not match the size of *X* (see\n",
      ":doc:`/gallery/images_contours_and_fields/image_antialiasing`).\n",
      "The resampling can be controlled via the *interpolation* parameter\n",
      "and/or :rc:`image.interpolation`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "X : array-like or PIL image\n",
      "    The image data. Supported array shapes are:\n",
      "\n",
      "    - (M, N): an image with scalar data. The values are mapped to\n",
      "      colors using normalization and a colormap. See parameters *norm*,\n",
      "      *cmap*, *vmin*, *vmax*.\n",
      "    - (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
      "    - (M, N, 4): an image with RGBA values (0-1 float or 0-255 int),\n",
      "      i.e. including transparency.\n",
      "\n",
      "    The first two dimensions (M, N) define the rows and columns of\n",
      "    the image.\n",
      "\n",
      "    Out-of-range RGB(A) values are clipped.\n",
      "\n",
      "cmap : str or `~matplotlib.colors.Colormap`, default: :rc:`image.cmap`\n",
      "    The Colormap instance or registered colormap name used to map scalar data\n",
      "    to colors.\n",
      "\n",
      "    This parameter is ignored if *X* is RGB(A).\n",
      "\n",
      "norm : str or `~matplotlib.colors.Normalize`, optional\n",
      "    The normalization method used to scale scalar data to the [0, 1] range\n",
      "    before mapping to colors using *cmap*. By default, a linear scaling is\n",
      "    used, mapping the lowest value to 0 and the highest to 1.\n",
      "\n",
      "    If given, this can be one of the following:\n",
      "\n",
      "    - An instance of `.Normalize` or one of its subclasses\n",
      "      (see :doc:`/tutorials/colors/colormapnorms`).\n",
      "    - A scale name, i.e. one of \"linear\", \"log\", \"symlog\", \"logit\", etc.  For a\n",
      "      list of available scales, call `matplotlib.scale.get_scale_names()`.\n",
      "      In that case, a suitable `.Normalize` subclass is dynamically generated\n",
      "      and instantiated.\n",
      "\n",
      "    This parameter is ignored if *X* is RGB(A).\n",
      "\n",
      "vmin, vmax : float, optional\n",
      "    When using scalar data and no explicit *norm*, *vmin* and *vmax* define\n",
      "    the data range that the colormap covers. By default, the colormap covers\n",
      "    the complete value range of the supplied data. It is an error to use\n",
      "    *vmin*/*vmax* when a *norm* instance is given (but using a `str` *norm*\n",
      "    name together with *vmin*/*vmax* is acceptable).\n",
      "\n",
      "    This parameter is ignored if *X* is RGB(A).\n",
      "\n",
      "aspect : {'equal', 'auto'} or float, default: :rc:`image.aspect`\n",
      "    The aspect ratio of the Axes.  This parameter is particularly\n",
      "    relevant for images since it determines whether data pixels are\n",
      "    square.\n",
      "\n",
      "    This parameter is a shortcut for explicitly calling\n",
      "    `.Axes.set_aspect`. See there for further details.\n",
      "\n",
      "    - 'equal': Ensures an aspect ratio of 1. Pixels will be square\n",
      "      (unless pixel sizes are explicitly made non-square in data\n",
      "      coordinates using *extent*).\n",
      "    - 'auto': The Axes is kept fixed and the aspect is adjusted so\n",
      "      that the data fit in the Axes. In general, this will result in\n",
      "      non-square pixels.\n",
      "\n",
      "interpolation : str, default: :rc:`image.interpolation`\n",
      "    The interpolation method used.\n",
      "\n",
      "    Supported values are 'none', 'antialiased', 'nearest', 'bilinear',\n",
      "    'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite',\n",
      "    'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell',\n",
      "    'sinc', 'lanczos', 'blackman'.\n",
      "\n",
      "    If *interpolation* is 'none', then no interpolation is performed\n",
      "    on the Agg, ps, pdf and svg backends. Other backends will fall back\n",
      "    to 'nearest'. Note that most SVG renderers perform interpolation at\n",
      "    rendering and that the default interpolation method they implement\n",
      "    may differ.\n",
      "\n",
      "    If *interpolation* is the default 'antialiased', then 'nearest'\n",
      "    interpolation is used if the image is upsampled by more than a\n",
      "    factor of three (i.e. the number of display pixels is at least\n",
      "    three times the size of the data array).  If the upsampling rate is\n",
      "    smaller than 3, or the image is downsampled, then 'hanning'\n",
      "    interpolation is used to act as an anti-aliasing filter, unless the\n",
      "    image happens to be upsampled by exactly a factor of two or one.\n",
      "\n",
      "    See\n",
      "    :doc:`/gallery/images_contours_and_fields/interpolation_methods`\n",
      "    for an overview of the supported interpolation methods, and\n",
      "    :doc:`/gallery/images_contours_and_fields/image_antialiasing` for\n",
      "    a discussion of image antialiasing.\n",
      "\n",
      "    Some interpolation methods require an additional radius parameter,\n",
      "    which can be set by *filterrad*. Additionally, the antigrain image\n",
      "    resize filter is controlled by the parameter *filternorm*.\n",
      "\n",
      "interpolation_stage : {'data', 'rgba'}, default: 'data'\n",
      "    If 'data', interpolation\n",
      "    is carried out on the data provided by the user.  If 'rgba', the\n",
      "    interpolation is carried out after the colormapping has been\n",
      "    applied (visual interpolation).\n",
      "\n",
      "alpha : float or array-like, optional\n",
      "    The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
      "    If *alpha* is an array, the alpha blending values are applied pixel\n",
      "    by pixel, and *alpha* must have the same shape as *X*.\n",
      "\n",
      "origin : {'upper', 'lower'}, default: :rc:`image.origin`\n",
      "    Place the [0, 0] index of the array in the upper left or lower\n",
      "    left corner of the Axes. The convention (the default) 'upper' is\n",
      "    typically used for matrices and images.\n",
      "\n",
      "    Note that the vertical axis points upward for 'lower'\n",
      "    but downward for 'upper'.\n",
      "\n",
      "    See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
      "    examples and a more detailed description.\n",
      "\n",
      "extent : floats (left, right, bottom, top), optional\n",
      "    The bounding box in data coordinates that the image will fill.\n",
      "    These values may be unitful and match the units of the Axes.\n",
      "    The image is stretched individually along x and y to fill the box.\n",
      "\n",
      "    The default extent is determined by the following conditions.\n",
      "    Pixels have unit size in data coordinates. Their centers are on\n",
      "    integer coordinates, and their center coordinates range from 0 to\n",
      "    columns-1 horizontally and from 0 to rows-1 vertically.\n",
      "\n",
      "    Note that the direction of the vertical axis and thus the default\n",
      "    values for top and bottom depend on *origin*:\n",
      "\n",
      "    - For ``origin == 'upper'`` the default is\n",
      "      ``(-0.5, numcols-0.5, numrows-0.5, -0.5)``.\n",
      "    - For ``origin == 'lower'`` the default is\n",
      "      ``(-0.5, numcols-0.5, -0.5, numrows-0.5)``.\n",
      "\n",
      "    See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
      "    examples and a more detailed description.\n",
      "\n",
      "filternorm : bool, default: True\n",
      "    A parameter for the antigrain image resize filter (see the\n",
      "    antigrain documentation).  If *filternorm* is set, the filter\n",
      "    normalizes integer values and corrects the rounding errors. It\n",
      "    doesn't do anything with the source floating point values, it\n",
      "    corrects only integers according to the rule of 1.0 which means\n",
      "    that any sum of pixel weights must be equal to 1.0.  So, the\n",
      "    filter function must produce a graph of the proper shape.\n",
      "\n",
      "filterrad : float > 0, default: 4.0\n",
      "    The filter radius for filters that have a radius parameter, i.e.\n",
      "    when interpolation is one of: 'sinc', 'lanczos' or 'blackman'.\n",
      "\n",
      "resample : bool, default: :rc:`image.resample`\n",
      "    When *True*, use a full resampling method.  When *False*, only\n",
      "    resample when the output image is larger than the input image.\n",
      "\n",
      "url : str, optional\n",
      "    Set the url of the created `.AxesImage`. See `.Artist.set_url`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "`~matplotlib.image.AxesImage`\n",
      "\n",
      "Other Parameters\n",
      "----------------\n",
      "data : indexable object, optional\n",
      "    If given, all parameters also accept a string ``s``, which is\n",
      "    interpreted as ``data[s]`` (unless this raises an exception).\n",
      "\n",
      "**kwargs : `~matplotlib.artist.Artist` properties\n",
      "    These parameters are passed on to the constructor of the\n",
      "    `.AxesImage` artist.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "matshow : Plot a matrix or an array as an image.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Unless *extent* is used, pixel centers will be located at integer\n",
      "coordinates. In other words: the origin will coincide with the center\n",
      "of pixel (0, 0).\n",
      "\n",
      "There are two common representations for RGB images with an alpha\n",
      "channel:\n",
      "\n",
      "-   Straight (unassociated) alpha: R, G, and B channels represent the\n",
      "    color of the pixel, disregarding its opacity.\n",
      "-   Premultiplied (associated) alpha: R, G, and B channels represent\n",
      "    the color of the pixel, adjusted for its opacity by multiplication.\n",
      "\n",
      "`~matplotlib.pyplot.imshow` expects RGB images adopting the straight\n",
      "(unassociated) alpha representation.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minterpolation_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m__ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minterpolation_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation_stage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "plt.imshow??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow dependencies - functional API\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup gpu\n",
    "#limit how much vram can use avoid OOM errors by setting memory consumption growth\n",
    "gpus = tf.config.experimental.list_physical_devices(\"gpu\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/positive'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'data/positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOS_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(NEG_PATH)\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(ANC_PATH)\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'data/positive'"
     ]
    }
   ],
   "source": [
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncompress the tar file of faces in the wild dataset\n",
    "\n",
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put our pics in the right folder\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH =  os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import uuid library to give unique names to each of our images collected\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18b7a1a8-4393-11ef-90ac-5a61087f7887.jpg'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '{}.jpg'.format(uuid.uuid1())#test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up connection to webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #slice x, y, and color channel axis to create 250x250 pixel image\n",
    "    frame = frame[350:350+250,950:950+250, :]\n",
    "\n",
    "    #collect anchors\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        #create unique file path\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        #write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "\n",
    "    #collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "    #show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    #Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "waitKey([, delay]) -> retval\n",
      ".   @brief Waits for a pressed key.\n",
      ".   \n",
      ".   The function waitKey waits for a key event infinitely (when \\f$\\texttt{delay}\\leq 0\\f$ ) or for delay\n",
      ".   milliseconds, when it is positive. Since the OS has a minimum time between switching threads, the\n",
      ".   function will not wait exactly delay ms, it will wait at least delay ms, depending on what else is\n",
      ".   running on your computer at that time. It returns the code of the pressed key or -1 if no key was\n",
      ".   pressed before the specified time had elapsed. To check for a key press but not wait for it, use\n",
      ".   #pollKey.\n",
      ".   \n",
      ".   @note The functions #waitKey and #pollKey are the only methods in HighGUI that can fetch and handle\n",
      ".   GUI events, so one of them needs to be called periodically for normal event processing unless\n",
      ".   HighGUI is used within an environment that takes care of event processing.\n",
      ".   \n",
      ".   @note The function only works if there is at least one HighGUI window created and the window is\n",
      ".   active. If there are several HighGUI windows, any of them can be active.\n",
      ".   \n",
      ".   @param delay Delay in milliseconds. 0 is the special value that means \"forever\".\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv2.waitKey??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and preprocess images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use *wildcard to grab all files in anc_path with jpg file type. can use this with any file type compatible with tf\n",
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = anchor.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data/anchor/dc61c9ee-4393-11ef-90ac-5a61087f7887.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see what it does\n",
    "dir_test.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale and resize    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    #read in image from file path and assign to new variable\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    #load in image and decode jpeg\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    #preprocessing steps - resize image to 100, 100 pixels, 3 channels\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    #scale image to be between 0 and 1... this takes every pixel value from original of 0-255 and makes it 0-1\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess(\"data/anchor/d9702762-4393-11ef-90ac-5a61087f7887.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.024019608, 0.8507353)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.numpy().min(), img.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create labeled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to create positive and negative examples\n",
    "#anchor and positive = 1\n",
    "#anchor and negative = 0\n",
    "\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a single sample \n",
    "example = samples.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build train and test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, val_img, label):\n",
    "    return(preprocess(input_img), preprocess(val_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)\n",
    "plt.imshow(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29efa6250>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(samp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD our siamese NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3)) #100 X 100 pixels, 3 color channels\n",
    "\n",
    "    #convolution takes the number of filters we want to pass through, sometimes we would specify stride, which tells how many pixels to traverse\n",
    "    #at a time.\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp) #64 filters, shape 10 x 10 pixels, relu activation, passing input to the layer\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1) #we take max value from 2x2 area\n",
    "\n",
    "    #second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "\n",
    "    #third block\n",
    "    c3 = Conv2D(128, (4,4), activation = 'relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "\n",
    "    #final feature block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4) #take 3 dimension convolution layer and flatten into a single dimension\n",
    "    d1 = Dense(4096, activation = 'sigmoid')(f1)\n",
    "\n",
    "\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding  = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"embedding\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"embedding\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">37,752,832</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m19,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m401,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m37,752,832\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> (148.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,960,448\u001b[0m (148.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> (148.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,960,448\u001b[0m (148.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build L1 Siamese distance layer.. will tell us how similar our images are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1 distance class\n",
    "class L1Dist(Layer):\n",
    "    #this creates a custom neural network layer. We have defined so when we export model, we can bring this layer along with us.\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__() #inherit methods from Layer class from Keras\n",
    "    \n",
    "    def call(self, input_embedding, validation_embedding): #our two photos' embeddings are brought together here.\n",
    "        input_embedding = tf.convert_to_tensor(input_embedding)\n",
    "        validation_embedding = tf.convert_to_tensor(validation_embedding)\n",
    "        input_embedding = tf.squeeze(input_embedding, axis=0) #remove potential first dimension\n",
    "        validation_embedding = tf.squeeze(validation_embedding, axis=0)\n",
    "        return tf.math.abs(input_embedding - validation_embedding) #return absolute value of the difference between our two photos' embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring everything together in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(name='input_img', shape=(100,100,3))\n",
    "validation_image = Input(name='validation_img', shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_embedding = embedding(input_image)\n",
    "val_embedding = embedding(validation_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_layer = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_32>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_layer(inp_embedding,val_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "\n",
    "    #handle inputs\n",
    "    #anchor img in network\n",
    "    input_image = Input(name='input_img', shape = (100,100,3))\n",
    "    #validation img in network\n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "\n",
    "    #combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "    #classification layer\n",
    "    classifier = Dense(1, activation = 'sigmoid')(distances)\n",
    "\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name = 'SiameseNetwork')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseNetwork = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseNetwork.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a loss function\n",
    "binary_cross_loss = tf.losses.BinaryCrossentropy() #you can pass from_logits = True if your inputs to loss function aren't normalized.\n",
    "#set up our optimizer for back prop\n",
    "opt = tf.keras.optimizers.Adam(1e-4) #0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=SiameseNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the custom training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = train_data.as_numpy_iterator()\n",
    "batch_1 = test_batch.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_1[0]) #16 images in first part of batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_1[1]) #16 images in positive/negative image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_1[2]) #16 scalars either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_1[:2]\n",
    "y = batch_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 100, 100, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape #2 arrays of 16 images each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape: #lets us capture our NN gradients for differentiation\n",
    "        #get anchor and positive/negative image\n",
    "        X = batch[:2] #grab our two image arrays\n",
    "        #get label\n",
    "        y = batch[2]\n",
    "\n",
    "        #forward pass\n",
    "        yhat = SiameseNetwork(X, training=True)\n",
    "\n",
    "        #loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    \n",
    "    #gradients\n",
    "    grad = tape.gradient(loss, SiameseNetwork.trainable_variables)\n",
    "\n",
    "    #calculate updated weights and apply to network\n",
    "    opt.apply_gradients(zip(grad, SiameseNetwork.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create our training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    #loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        total_loss = 0\n",
    "\n",
    "        #loop trhough each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            #run train step here and capture loss\n",
    "            loss = train_step(batch)\n",
    "            total_loss += loss\n",
    "            #update progress bar with current batch loss\n",
    "            progbar.update(idx+1, values=[(\"loss\", loss)])\n",
    "        #calculate average loss for the epoch\n",
    "        avg_loss = total_loss / len(data)\n",
    "        print(f\"Average loss for Epoch {epoch}: {avg_loss:.4f}\")\n",
    "\n",
    "        #save checkpoints\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - loss: 0.1241\n",
      "Average loss for Epoch 1: 0.1241\n",
      "\n",
      " Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.1256\n",
      "Average loss for Epoch 2: 0.1256\n",
      "\n",
      " Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0284\n",
      "Average loss for Epoch 3: 0.0284\n",
      "\n",
      " Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0120\n",
      "Average loss for Epoch 4: 0.0120\n",
      "\n",
      " Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 11:38:39.201852: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0077\n",
      "Average loss for Epoch 5: 0.0077\n",
      "\n",
      " Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 0.0059\n",
      "Average loss for Epoch 6: 0.0059\n",
      "\n",
      " Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0060\n",
      "Average loss for Epoch 7: 0.0060\n",
      "\n",
      " Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0031\n",
      "Average loss for Epoch 8: 0.0031\n",
      "\n",
      " Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0028\n",
      "Average loss for Epoch 9: 0.0028\n",
      "\n",
      " Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0023\n",
      "Average loss for Epoch 10: 0.0023\n",
      "\n",
      " Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0028\n",
      "Average loss for Epoch 11: 0.0028\n",
      "\n",
      " Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0019\n",
      "Average loss for Epoch 12: 0.0019\n",
      "\n",
      " Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0017\n",
      "Average loss for Epoch 13: 0.0017\n",
      "\n",
      " Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0017\n",
      "Average loss for Epoch 14: 0.0017\n",
      "\n",
      " Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 0.0012\n",
      "Average loss for Epoch 15: 0.0012\n",
      "\n",
      " Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0011\n",
      "Average loss for Epoch 16: 0.0011\n",
      "\n",
      " Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0011   \n",
      "Average loss for Epoch 17: 0.0011\n",
      "\n",
      " Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 8.1022e-04\n",
      "Average loss for Epoch 18: 0.0008\n",
      "\n",
      " Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 8.5609e-04\n",
      "Average loss for Epoch 19: 0.0009\n",
      "\n",
      " Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 9.0941e-04\n",
      "Average loss for Epoch 20: 0.0009\n",
      "\n",
      " Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 6.3836e-04\n",
      "Average loss for Epoch 21: 0.0006\n",
      "\n",
      " Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 0.0011   \n",
      "Average loss for Epoch 22: 0.0011\n",
      "\n",
      " Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 6.9023e-04\n",
      "Average loss for Epoch 23: 0.0007\n",
      "\n",
      " Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 6.6083e-04\n",
      "Average loss for Epoch 24: 0.0007\n",
      "\n",
      " Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 5.0471e-04\n",
      "Average loss for Epoch 25: 0.0005\n",
      "\n",
      " Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 4.5692e-04\n",
      "Average loss for Epoch 26: 0.0005\n",
      "\n",
      " Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 3.9387e-04\n",
      "Average loss for Epoch 27: 0.0004\n",
      "\n",
      " Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 4.3797e-04\n",
      "Average loss for Epoch 28: 0.0004\n",
      "\n",
      " Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 3.6942e-04\n",
      "Average loss for Epoch 29: 0.0004\n",
      "\n",
      " Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 4.0416e-04\n",
      "Average loss for Epoch 30: 0.0004\n",
      "\n",
      " Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 3.1228e-04\n",
      "Average loss for Epoch 31: 0.0003\n",
      "\n",
      " Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 3.5348e-04\n",
      "Average loss for Epoch 32: 0.0004\n",
      "\n",
      " Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 3.3562e-04\n",
      "Average loss for Epoch 33: 0.0003\n",
      "\n",
      " Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 3.0794e-04\n",
      "Average loss for Epoch 34: 0.0003\n",
      "\n",
      " Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 4.3084e-04\n",
      "Average loss for Epoch 35: 0.0004\n",
      "\n",
      " Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 3.4274e-04\n",
      "Average loss for Epoch 36: 0.0003\n",
      "\n",
      " Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 3.2717e-04\n",
      "Average loss for Epoch 37: 0.0003\n",
      "\n",
      " Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.8643e-04\n",
      "Average loss for Epoch 38: 0.0003\n",
      "\n",
      " Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.4303e-04\n",
      "Average loss for Epoch 39: 0.0002\n",
      "\n",
      " Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.2237e-04\n",
      "Average loss for Epoch 40: 0.0002\n",
      "\n",
      " Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 2.3702e-04\n",
      "Average loss for Epoch 41: 0.0002\n",
      "\n",
      " Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.3259e-04\n",
      "Average loss for Epoch 42: 0.0002\n",
      "\n",
      " Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.3481e-04\n",
      "Average loss for Epoch 43: 0.0002\n",
      "\n",
      " Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.3357e-04\n",
      "Average loss for Epoch 44: 0.0002\n",
      "\n",
      " Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.4866e-04\n",
      "Average loss for Epoch 45: 0.0002\n",
      "\n",
      " Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 2.0498e-04\n",
      "Average loss for Epoch 46: 0.0002\n",
      "\n",
      " Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 1.5250e-04\n",
      "Average loss for Epoch 47: 0.0002\n",
      "\n",
      " Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 1.7679e-04\n",
      "Average loss for Epoch 48: 0.0002\n",
      "\n",
      " Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 1.7039e-04\n",
      "Average loss for Epoch 49: 0.0002\n",
      "\n",
      " Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 1.8831e-04\n",
      "Average loss for Epoch 50: 0.0002\n"
     ]
    }
   ],
   "source": [
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import evaluation metrics\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next() #converts tf tensor into numpy equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.7732843 , 0.7615196 , 0.7026961 ],\n",
       "         [0.7764706 , 0.7647059 , 0.7058824 ],\n",
       "         [0.7764706 , 0.7647059 , 0.7058824 ],\n",
       "         ...,\n",
       "         [0.5264706 , 0.50686276, 0.48333332],\n",
       "         [0.7264706 , 0.70686275, 0.68333334],\n",
       "         [0.7382353 , 0.71862745, 0.69509804]],\n",
       "\n",
       "        [[0.77254903, 0.7607843 , 0.7019608 ],\n",
       "         [0.7747549 , 0.7639706 , 0.7051471 ],\n",
       "         [0.7754902 , 0.7647059 , 0.7058824 ],\n",
       "         ...,\n",
       "         [0.5264706 , 0.50784314, 0.4715686 ],\n",
       "         [0.6730392 , 0.6544118 , 0.61813724],\n",
       "         [0.7267157 , 0.7080882 , 0.6718137 ]],\n",
       "\n",
       "        [[0.77254903, 0.7607843 , 0.7019608 ],\n",
       "         [0.76862746, 0.7607843 , 0.7019608 ],\n",
       "         [0.76936275, 0.7615196 , 0.7026961 ],\n",
       "         ...,\n",
       "         [0.51666665, 0.48333332, 0.44705883],\n",
       "         [0.55245095, 0.51911765, 0.48284313],\n",
       "         [0.6781863 , 0.6507353 , 0.61151963]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784315, 0.7607843 , 0.69803923],\n",
       "         [0.80759805, 0.76053923, 0.69779414],\n",
       "         [0.8068628 , 0.75980395, 0.6970588 ],\n",
       "         ...,\n",
       "         [0.77181375, 0.7443628 , 0.6737745 ],\n",
       "         [0.77181375, 0.7443628 , 0.6737745 ],\n",
       "         [0.77254903, 0.74509805, 0.6745098 ]],\n",
       "\n",
       "        [[0.8009804 , 0.75392157, 0.6911765 ],\n",
       "         [0.8039216 , 0.75686276, 0.69411767],\n",
       "         [0.8039216 , 0.75686276, 0.69411767],\n",
       "         ...,\n",
       "         [0.77254903, 0.74509805, 0.6789216 ],\n",
       "         [0.7754902 , 0.7480392 , 0.67745095],\n",
       "         [0.76862746, 0.7411765 , 0.67058825]],\n",
       "\n",
       "        [[0.8       , 0.7529412 , 0.6901961 ],\n",
       "         [0.8009804 , 0.75392157, 0.6911765 ],\n",
       "         [0.8039216 , 0.75686276, 0.69411767],\n",
       "         ...,\n",
       "         [0.7705882 , 0.74313724, 0.6784314 ],\n",
       "         [0.77254903, 0.74509805, 0.6745098 ],\n",
       "         [0.7754902 , 0.7480392 , 0.67745095]]],\n",
       "\n",
       "\n",
       "       [[[0.76960784, 0.75392157, 0.70686275],\n",
       "         [0.77254903, 0.75686276, 0.70980394],\n",
       "         [0.7703431 , 0.75465685, 0.70759803],\n",
       "         ...,\n",
       "         [0.7497549 , 0.7379902 , 0.7105392 ],\n",
       "         [0.7529412 , 0.7411765 , 0.7137255 ],\n",
       "         [0.74607843, 0.7343137 , 0.70686275]],\n",
       "\n",
       "        [[0.77254903, 0.75686276, 0.70980394],\n",
       "         [0.77254903, 0.75686276, 0.70980394],\n",
       "         [0.7703431 , 0.75465685, 0.70759803],\n",
       "         ...,\n",
       "         [0.7561275 , 0.7443628 , 0.7169118 ],\n",
       "         [0.7529412 , 0.7411765 , 0.7137255 ],\n",
       "         [0.75392157, 0.74215686, 0.7147059 ]],\n",
       "\n",
       "        [[0.76936275, 0.7536765 , 0.70661765],\n",
       "         [0.7703431 , 0.75465685, 0.70759803],\n",
       "         [0.7703431 , 0.75465685, 0.70759803],\n",
       "         ...,\n",
       "         [0.7585784 , 0.7468137 , 0.71936274],\n",
       "         [0.76004905, 0.74828434, 0.72083336],\n",
       "         [0.7529412 , 0.7411765 , 0.7137255 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.53406864, 0.3482843 , 0.28627452],\n",
       "         [0.5095588 , 0.32990196, 0.264951  ],\n",
       "         [0.45392156, 0.28529412, 0.21715686],\n",
       "         ...,\n",
       "         [0.7678922 , 0.7404412 , 0.67769605],\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ],\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ]],\n",
       "\n",
       "        [[0.51936275, 0.34534314, 0.28039217],\n",
       "         [0.48578432, 0.31789216, 0.25196078],\n",
       "         [0.40955883, 0.25465685, 0.1870098 ],\n",
       "         ...,\n",
       "         [0.7678922 , 0.7404412 , 0.6718137 ],\n",
       "         [0.76862746, 0.7411765 , 0.672549  ],\n",
       "         [0.7656863 , 0.7382353 , 0.6696078 ]],\n",
       "\n",
       "        [[0.5147059 , 0.34607843, 0.28333333],\n",
       "         [0.46568626, 0.30392158, 0.24019608],\n",
       "         [0.37745097, 0.23039216, 0.16666667],\n",
       "         ...,\n",
       "         [0.76862746, 0.7411765 , 0.67058825],\n",
       "         [0.77254903, 0.74509805, 0.6745098 ],\n",
       "         [0.77254903, 0.74509805, 0.6745098 ]]],\n",
       "\n",
       "\n",
       "       [[[0.78063726, 0.75710785, 0.69436276],\n",
       "         [0.7830882 , 0.7625    , 0.6987745 ],\n",
       "         [0.78039217, 0.76862746, 0.7019608 ],\n",
       "         ...,\n",
       "         [0.74509805, 0.74215686, 0.70392156],\n",
       "         [0.7495098 , 0.7348039 , 0.6995098 ],\n",
       "         [0.7519608 , 0.7362745 , 0.70098037]],\n",
       "\n",
       "        [[0.78137255, 0.7607843 , 0.6970588 ],\n",
       "         [0.7754902 , 0.7637255 , 0.6990196 ],\n",
       "         [0.7742647 , 0.7625    , 0.69779414],\n",
       "         ...,\n",
       "         [0.7531863 , 0.7411765 , 0.7058824 ],\n",
       "         [0.7583333 , 0.74338233, 0.7080882 ],\n",
       "         [0.7529412 , 0.7372549 , 0.7019608 ]],\n",
       "\n",
       "        [[0.7732843 , 0.7644608 , 0.70367646],\n",
       "         [0.76862746, 0.75980395, 0.702451  ],\n",
       "         [0.79044116, 0.7772059 , 0.7264706 ],\n",
       "         ...,\n",
       "         [0.7607843 , 0.74583334, 0.7105392 ],\n",
       "         [0.7585784 , 0.74289215, 0.70759803],\n",
       "         [0.75686276, 0.7411765 , 0.7058824 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7882353 , 0.7372549 , 0.6745098 ],\n",
       "         [0.7921569 , 0.7411765 , 0.6784314 ],\n",
       "         [0.7921569 , 0.7411765 , 0.6784314 ],\n",
       "         ...,\n",
       "         [0.76862746, 0.7411765 , 0.6764706 ],\n",
       "         [0.7647059 , 0.7372549 , 0.672549  ],\n",
       "         [0.76862746, 0.7411765 , 0.6764706 ]],\n",
       "\n",
       "        [[0.7882353 , 0.7372549 , 0.6745098 ],\n",
       "         [0.7892157 , 0.7382353 , 0.6754902 ],\n",
       "         [0.7921569 , 0.7411765 , 0.6784314 ],\n",
       "         ...,\n",
       "         [0.76862746, 0.7411765 , 0.67058825],\n",
       "         [0.76862746, 0.7411765 , 0.67058825],\n",
       "         [0.76862746, 0.7411765 , 0.67058825]],\n",
       "\n",
       "        [[0.7882353 , 0.7372549 , 0.6745098 ],\n",
       "         [0.7882353 , 0.7372549 , 0.6745098 ],\n",
       "         [0.7911765 , 0.74019605, 0.67745095],\n",
       "         ...,\n",
       "         [0.7644608 , 0.7370098 , 0.6664216 ],\n",
       "         [0.7654412 , 0.7379902 , 0.66740197],\n",
       "         [0.76960784, 0.74215686, 0.67156863]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.79558825, 0.7759804 , 0.76029414],\n",
       "         [0.6512255 , 0.63161767, 0.6139706 ],\n",
       "         [0.36691177, 0.34730393, 0.32377452],\n",
       "         ...,\n",
       "         [0.7480392 , 0.7480392 , 0.7088235 ],\n",
       "         [0.74215686, 0.74215686, 0.7029412 ],\n",
       "         [0.74509805, 0.74509805, 0.7058824 ]],\n",
       "\n",
       "        [[0.58235294, 0.54901963, 0.5392157 ],\n",
       "         [0.3615196 , 0.32818627, 0.31740198],\n",
       "         [0.24509804, 0.21470588, 0.19509804],\n",
       "         ...,\n",
       "         [0.7529412 , 0.7529412 , 0.7137255 ],\n",
       "         [0.7529412 , 0.7529412 , 0.7137255 ],\n",
       "         [0.7519608 , 0.7519608 , 0.7127451 ]],\n",
       "\n",
       "        [[0.28651962, 0.24142157, 0.24044117],\n",
       "         [0.23186274, 0.1875    , 0.18406862],\n",
       "         [0.22916667, 0.1877451 , 0.17769608],\n",
       "         ...,\n",
       "         [0.7529412 , 0.7529412 , 0.7137255 ],\n",
       "         [0.75      , 0.75      , 0.7107843 ],\n",
       "         [0.7519608 , 0.7519608 , 0.7127451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8117647 , 0.78039217, 0.7058824 ],\n",
       "         [0.8115196 , 0.7801471 , 0.7056373 ],\n",
       "         [0.81078434, 0.7794118 , 0.70490193],\n",
       "         ...,\n",
       "         [0.7762255 , 0.7526961 , 0.689951  ],\n",
       "         [0.7754902 , 0.7519608 , 0.68921566],\n",
       "         [0.7735294 , 0.75      , 0.6872549 ]],\n",
       "\n",
       "        [[0.8039216 , 0.77254903, 0.69803923],\n",
       "         [0.80490196, 0.7735294 , 0.6990196 ],\n",
       "         [0.8041667 , 0.7727941 , 0.6982843 ],\n",
       "         ...,\n",
       "         [0.7762255 , 0.7526961 , 0.689951  ],\n",
       "         [0.7732843 , 0.7497549 , 0.6870098 ],\n",
       "         [0.777451  , 0.75392157, 0.6911765 ]],\n",
       "\n",
       "        [[0.8039216 , 0.77254903, 0.69803923],\n",
       "         [0.80759805, 0.7762255 , 0.7017157 ],\n",
       "         [0.80759805, 0.7762255 , 0.7017157 ],\n",
       "         ...,\n",
       "         [0.77254903, 0.7490196 , 0.6862745 ],\n",
       "         [0.7764706 , 0.7529412 , 0.6901961 ],\n",
       "         [0.7754902 , 0.7519608 , 0.68921566]]],\n",
       "\n",
       "\n",
       "       [[[0.7982843 , 0.7982843 , 0.7590686 ],\n",
       "         [0.777451  , 0.777451  , 0.74019605],\n",
       "         [0.5205882 , 0.5176471 , 0.49509802],\n",
       "         ...,\n",
       "         [0.7487745 , 0.7370098 , 0.7017157 ],\n",
       "         [0.7512255 , 0.73946077, 0.70416665],\n",
       "         [0.7490196 , 0.7372549 , 0.7019608 ]],\n",
       "\n",
       "        [[0.7914216 , 0.7884804 , 0.7522059 ],\n",
       "         [0.56102943, 0.55735296, 0.5296569 ],\n",
       "         [0.21985294, 0.21323529, 0.19730392],\n",
       "         ...,\n",
       "         [0.7531863 , 0.7414216 , 0.70612746],\n",
       "         [0.7529412 , 0.7411765 , 0.7058824 ],\n",
       "         [0.7558824 , 0.7441176 , 0.7088235 ]],\n",
       "\n",
       "        [[0.65367645, 0.64191175, 0.62034315],\n",
       "         [0.2622549 , 0.2497549 , 0.23014706],\n",
       "         [0.21715686, 0.2017157 , 0.19387256],\n",
       "         ...,\n",
       "         [0.75392157, 0.7509804 , 0.7127451 ],\n",
       "         [0.7509804 , 0.7480392 , 0.70980394],\n",
       "         [0.75      , 0.7470588 , 0.7088235 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8039216 , 0.7607843 , 0.6901961 ],\n",
       "         [0.8039216 , 0.7607843 , 0.6901961 ],\n",
       "         [0.80710787, 0.7639706 , 0.6933824 ],\n",
       "         ...,\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ],\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ],\n",
       "         [0.7627451 , 0.7352941 , 0.672549  ]],\n",
       "\n",
       "        [[0.8039216 , 0.7607843 , 0.6901961 ],\n",
       "         [0.8039216 , 0.7607843 , 0.6901961 ],\n",
       "         [0.80490196, 0.7617647 , 0.6911765 ],\n",
       "         ...,\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ],\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ],\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ]],\n",
       "\n",
       "        [[0.8       , 0.75686276, 0.6862745 ],\n",
       "         [0.8       , 0.75686276, 0.6862745 ],\n",
       "         [0.8039216 , 0.7607843 , 0.6901961 ],\n",
       "         ...,\n",
       "         [0.77254903, 0.74509805, 0.68235296],\n",
       "         [0.77254903, 0.74509805, 0.68235296],\n",
       "         [0.76862746, 0.7411765 , 0.6784314 ]]],\n",
       "\n",
       "\n",
       "       [[[0.79387254, 0.77818626, 0.73112744],\n",
       "         [0.77843136, 0.76960784, 0.7254902 ],\n",
       "         [0.7477941 , 0.7360294 , 0.70661765],\n",
       "         ...,\n",
       "         [0.7588235 , 0.7470588 , 0.71960783],\n",
       "         [0.7529412 , 0.7411765 , 0.7137255 ],\n",
       "         [0.7558824 , 0.7441176 , 0.71666664]],\n",
       "\n",
       "        [[0.7823529 , 0.7735294 , 0.7294118 ],\n",
       "         [0.7647059 , 0.75514704, 0.7137255 ],\n",
       "         [0.47965688, 0.46789217, 0.4389706 ],\n",
       "         ...,\n",
       "         [0.7607843 , 0.7490196 , 0.72156864],\n",
       "         [0.7607843 , 0.7490196 , 0.72156864],\n",
       "         [0.75686276, 0.74509805, 0.7176471 ]],\n",
       "\n",
       "        [[0.7522059 , 0.7404412 , 0.7110294 ],\n",
       "         [0.4995098 , 0.48921567, 0.4617647 ],\n",
       "         [0.25710785, 0.2512255 , 0.22965686],\n",
       "         ...,\n",
       "         [0.7607843 , 0.7490196 , 0.72156864],\n",
       "         [0.75784314, 0.74607843, 0.71862745],\n",
       "         [0.7529412 , 0.7411765 , 0.7137255 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8235294 , 0.7764706 , 0.7137255 ],\n",
       "         [0.82254905, 0.7754902 , 0.7127451 ],\n",
       "         [0.8232843 , 0.7762255 , 0.7134804 ],\n",
       "         ...,\n",
       "         [0.7764706 , 0.7529412 , 0.6901961 ],\n",
       "         [0.7735294 , 0.75      , 0.6872549 ],\n",
       "         [0.7735294 , 0.75      , 0.6872549 ]],\n",
       "\n",
       "        [[0.82058823, 0.7735294 , 0.7107843 ],\n",
       "         [0.82279414, 0.7757353 , 0.7129902 ],\n",
       "         [0.82279414, 0.7757353 , 0.7129902 ],\n",
       "         ...,\n",
       "         [0.7764706 , 0.7529412 , 0.6901961 ],\n",
       "         [0.7757353 , 0.7522059 , 0.6894608 ],\n",
       "         [0.7735294 , 0.75      , 0.6872549 ]],\n",
       "\n",
       "        [[0.8156863 , 0.76862746, 0.7058824 ],\n",
       "         [0.8156863 , 0.76862746, 0.7058824 ],\n",
       "         [0.8156863 , 0.76862746, 0.7058824 ],\n",
       "         ...,\n",
       "         [0.7764706 , 0.7529412 , 0.6901961 ],\n",
       "         [0.7764706 , 0.7529412 , 0.6901961 ],\n",
       "         [0.7764706 , 0.7529412 , 0.6901961 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_var = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
       "array([[3.5901201e-07],\n",
       "       [1.7525857e-05],\n",
       "       [5.3031062e-08],\n",
       "       [1.5703159e-07],\n",
       "       [1.3008901e-05],\n",
       "       [7.6733733e-07],\n",
       "       [2.2431391e-06],\n",
       "       [2.5058186e-04],\n",
       "       [9.9909133e-01],\n",
       "       [2.1700264e-07],\n",
       "       [9.9826849e-01],\n",
       "       [7.3225368e-05],\n",
       "       [9.9983799e-01],\n",
       "       [7.2779159e-07],\n",
       "       [7.8571190e-08],\n",
       "       [9.9998969e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make predictions\n",
    "y_hat = SiameseNetwork([test_input, test_val])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#post process the results\n",
    "[1 if prediction > .5 else 0 for prediction in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #long way to do the above:\n",
    "# res = []\n",
    "# for prediction in y_hat:\n",
    "#     if prediction > .5:\n",
    "#         res.append(1)\n",
    "#     else:\n",
    "#         res.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a metric object\n",
    "m = Recall()\n",
    "#update the state, calculate the recall value\n",
    "m.update_state(y_true, y_hat)\n",
    "#return recall result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize results\n",
    "#plt size\n",
    "plt.figure(figsize=(18,8))\n",
    "\n",
    "#set first subplot - since we putting two plots side by side\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[0])\n",
    "#set second subplot\n",
    "plt.subplot(1,2,2) #first row in the two columns, value in the second column. \n",
    "plt.imshow(test_val[0])\n",
    "\n",
    "#render the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#save weights\n",
    "SiameseNetwork.save('siamesemodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#reload model\n",
    "model = tf.keras.models.load_model('siamesemodel.h5',\n",
    "                                   custom_objects={'L1Dist': L1Dist, 'BinaryCrossentropy': tf.losses.BinaryCrossentropy}) #need this custom objects to save our custom L1 layer.\n",
    "\n",
    "#can also use tf.keras.models.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.5901201e-07],\n",
       "       [1.7525857e-05],\n",
       "       [5.3031062e-08],\n",
       "       [1.5703159e-07],\n",
       "       [1.3008901e-05],\n",
       "       [7.6733733e-07],\n",
       "       [2.2431391e-06],\n",
       "       [2.5058186e-04],\n",
       "       [9.9909133e-01],\n",
       "       [2.1700264e-07],\n",
       "       [9.9826849e-01],\n",
       "       [7.3225368e-05],\n",
       "       [9.9983799e-01],\n",
       "       [7.2779159e-07],\n",
       "       [7.8571190e-08],\n",
       "       [9.9998969e-01]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make prediction for testing reloaded model\n",
    "model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SiameseNetwork\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SiameseNetwork\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_img           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_img      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> │ input_img[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ validation_img[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L1Dist</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> │ l1_dist_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_img           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_img      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │ \u001b[38;5;34m38,960,448\u001b[0m │ input_img[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ validation_img[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_5 (\u001b[38;5;33mL1Dist\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m4,097\u001b[0m │ l1_dist_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reload model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real time testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica4tion function\n",
    "def verify(model, det_thres, ver_thres):\n",
    "    '''Detection threshold: metric above which a prediction is considered positive\n",
    "    ver threshold: proportion of positive predictions/ total positive samples'''\n",
    "\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
    "\n",
    "        #make predictions\n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis = 1)))\n",
    "        results.append(result)\n",
    "\n",
    "\n",
    "    #detection threshold\n",
    "    detection = np.sum(np.array(results) > det_thres)\n",
    "\n",
    "    #verification threshold\n",
    "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images')))\n",
    "    verified = verification > ver_thres\n",
    "\n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "True\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    #slice x, y, and color channel axis to create 250x250 pixel image\n",
    "    frame = frame[350:350+250,950:950+250, :]\n",
    "    cv2.imshow('Verification', frame)\n",
    "\n",
    "    #verification trigger\n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        #save input image\n",
    "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
    "        #run verification\n",
    "        results, verified = verify(model, .5, .5)\n",
    "        print(verified)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.squeeze(results) > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
